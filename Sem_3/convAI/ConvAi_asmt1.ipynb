{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d3d14dc",
      "metadata": {
        "id": "3d3d14dc"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git -q\n",
        "!pip install bitsandbytes datasets accelerate loralib -q\n",
        "# !pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cu11.8/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fac15894",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "36d680bd97bf49e5888e47c13f8fee38",
            "f9a06f3125a54bce92f0b218a502a0fc",
            "6b555c037c9840a6ad491ccd8c1e0310",
            "a5e88d16c2c34d16957152ddaa02b324",
            "4b8bec77ccf149babd8ebe37235cd503",
            "7cf859ed87094cdc829ae0f5e05de886",
            "2e8f41cba5634748a954ef5643b86fea",
            "d5155fe7e40a475f8c2a46d1c16713ec",
            "5919898f5bdc407399b4c4e46349f358",
            "51217dc25a2f45eda974840ebc9c9d67",
            "6bd825bedc204abbbef09f8746db0762",
            "98d5bab48f2545f992c3864e569420b7",
            "114858f44b5c4744a276f1e75c291301",
            "efc2b1c66f93433bb4e1991919cdc05b",
            "c5746add033b40399a239126506a9b41",
            "77332adfc67d4da38d470089138c4dea",
            "6efa4cc8b37c4fd29257154fbffda330",
            "95fbeed6b2fa4f32a207d043431ec9e4",
            "bb2f351428dd4607b9b3f03445104945",
            "9a1dc06baa4e426694c1c01f939486f7",
            "a901efa0220b4b148bae2f5c1c0262f3",
            "f915a8f3273a42fbb937e5790edfe363",
            "13d9bd613e314b2eb23104b213ba8fc5",
            "79a95416346941f8b3e15a570dfabd51",
            "8573fc25e94243eb994bcaa623f0c2a2",
            "67d2cacbbbf44d48a8b7bb5a8e1e403d",
            "55a8a1536da44d179ff557f13a9d6e77",
            "c7a1a5d9d9df4581bd867ffd6cd509b1",
            "2f692ace624444138724a0766fdf7157",
            "32d38418feb847bab2abe8e2645bd902",
            "4050313a5b364cc9bf3a0ceb12cb6f5f",
            "cb311ea899874ab7af71176554b9e1a8"
          ]
        },
        "id": "fac15894",
        "outputId": "06aea29c-c817-4367-caa0-3167d5aa49c4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36d680bd97bf49e5888e47c13f8fee38"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n",
        "token = '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'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "739ea420",
      "metadata": {
        "id": "739ea420"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import pandas as pd\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "# from accelerate import Accelerator\n",
        "# from accelerate.utils import write_basic_config\n",
        "\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, RobertaTokenizer, GPT2Tokenizer, \\\n",
        "    GPT2LMHeadModel, AutoTokenizer, AutoModelForCausalLM, AdamW\n",
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, decoders, processors\n",
        "\n",
        "# torch.random.manual_seed(0)\n",
        "# torch.cuda.set_device(0)\n",
        "# # torch.cuda.set_device(1)\n",
        "# # torch.cuda.set_device(2)\n",
        "# # torch.cuda.set_device(3)\n",
        "# torch.cuda.is_available()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a6255b2",
      "metadata": {
        "id": "1a6255b2"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling\n",
        "from datasets import load_dataset\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73e0129f",
      "metadata": {
        "id": "73e0129f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69089fb6",
      "metadata": {
        "id": "69089fb6"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "ds = load_dataset(\"nvidia/HelpSteer2\")\n",
        "train = ds['train'] # len(train) = 20324 (95%)\n",
        "val = ds['validation']     # len(val) = 1038 (5%)\n",
        "\n",
        "train_pd = pd.DataFrame(train)\n",
        "val_pd = pd.DataFrame(val)\n",
        "train_pd.head()\n",
        "val_pd.head()\n",
        "\n",
        "train_df = train_pd.copy()\n",
        "val_df = val_pd.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa142bb8",
      "metadata": {
        "id": "fa142bb8"
      },
      "source": [
        "## 1. no preprocessing needed for llm , lm preprocessing for lstm: [1 Mark]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c678645",
      "metadata": {
        "id": "5c678645"
      },
      "outputs": [],
      "source": [
        "train_pd = train_pd[:500]\n",
        "val_pd = val_pd[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5171e605",
      "metadata": {
        "id": "5171e605",
        "outputId": "3c29cba8-0e06-4e8e-91fb-846f682f63dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max token length of prompts and response:  548 1045\n",
            "Vocabulary size from train prompt + response  7095\n"
          ]
        }
      ],
      "source": [
        "# Tokenize the prompts and answers\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "# Build vocabulary\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_pd['prompt'].tolist() + train_pd['response'].tolist()),\n",
        "                                  specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "# Convert texts to sequences\n",
        "def text_pipeline(text):\n",
        "    return vocab(tokenizer(text))\n",
        "\n",
        "train_prompt_sequences = [text_pipeline(text) for text in train_pd['prompt']]\n",
        "train_answer_sequences = [text_pipeline(text) for text in train_pd['response']]\n",
        "val_prompt_sequences = [text_pipeline(text) for text in val_pd['prompt']]\n",
        "val_answer_sequences = [text_pipeline(text) for text in val_pd['response']]\n",
        "\n",
        "max_len_prompt = max(len(seq) for seq in train_prompt_sequences)\n",
        "max_len_answer = max(len(seq) for seq in train_answer_sequences)\n",
        "print('max token length of prompts and response: ', max_len_prompt, max_len_answer)\n",
        "# Vocabulary size\n",
        "vocab_size = len(vocab)\n",
        "print('Vocabulary size from train prompt + response ', vocab_size)\n",
        "\n",
        "# Pad the sequences\n",
        "def pad_sequences(sequences, max_len):\n",
        "    return pad_sequence([torch.tensor(seq[:max_len]) for seq in sequences], batch_first=True,\n",
        "                        padding_value=vocab[\"<unk>\"])\n",
        "\n",
        "train_prompt_sequences = pad_sequences(train_prompt_sequences, max_len_prompt)\n",
        "train_answer_sequences = pad_sequences(train_answer_sequences, max_len_answer)\n",
        "val_prompt_sequences = pad_sequences(val_prompt_sequences, max_len_prompt)\n",
        "val_answer_sequences = pad_sequences(val_answer_sequences, max_len_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "777b6a12",
      "metadata": {
        "id": "777b6a12",
        "outputId": "4233569f-d964-4864-cb8f-96cce03f3722"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([300, 548]),\n",
              " torch.Size([300, 1045]),\n",
              " torch.Size([50, 387]),\n",
              " torch.Size([50, 808]))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_prompt_sequences.shape, train_answer_sequences.shape, val_prompt_sequences.shape, val_answer_sequences.shape"
      ]
    },
    {
      "cell_type": "raw",
      "id": "52e8b088",
      "metadata": {
        "id": "52e8b088"
      },
      "source": [
        "Not sure why seq length isnt same for train and val"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "241f5d9c",
      "metadata": {
        "id": "241f5d9c"
      },
      "source": [
        "## 2.Explain and implement how LLM (2B to 8B parameters) over simple LM can help improve the system accuracy. [1 Mark]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12573dc5",
      "metadata": {
        "id": "12573dc5"
      },
      "outputs": [],
      "source": [
        "# Seq 2 Seq LM using lstm on Pytorch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.encoder_lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n",
        "        self.decoder_lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_units, vocab_size)\n",
        "\n",
        "    def forward(self, encoder_input, decoder_input, hidden):\n",
        "        encoder_embedded = self.embedding(encoder_input)\n",
        "        encoder_output, (hidden, cell) = self.encoder_lstm(encoder_embedded, hidden)\n",
        "\n",
        "        decoder_embedded = self.embedding(decoder_input)\n",
        "        decoder_output, (hidden, cell) = self.decoder_lstm(decoder_embedded, (hidden, cell))\n",
        "\n",
        "        output = self.fc(decoder_output)\n",
        "        return output, (hidden, cell)\n",
        "\n",
        "embedding_dim = 128\n",
        "hidden_units = 256\n",
        "\n",
        "model = Seq2Seq(vocab_size, embedding_dim, hidden_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a9b8b5a",
      "metadata": {
        "id": "6a9b8b5a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Hyperparameters\n",
        "num_epochs = 20\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "\n",
        "# Define the loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=vocab[\"<unk>\"])\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "device='cpu' # using cpu since gpu gives memory error\n",
        "# Move model to GPU\n",
        "# device_ids = [0, 1, 2, 3]  # Replace with desired GPU IDs\n",
        "# model = nn.DataParallel(model, device_ids=device_ids)\n",
        "# model.to(f'cuda:{device_ids[0]}')  # Move the model to the first GPU\n",
        "\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# # input_tensor = input_tensor.to(device)\n",
        "# model = model.to(device)\n",
        "\n",
        "# scaler = torch.cuda.amp.GradScaler()\n",
        "# Prepare the target data for the decoder (shifted one time step) !!!\n",
        "def prepare_target_sequences(sequences):\n",
        "    inputs = sequences[:, :-1]\n",
        "    targets = sequences[:, 1:]\n",
        "    return inputs, targets\n",
        "\n",
        "train_answer_sequences_input, train_answer_sequences_output = prepare_target_sequences(train_answer_sequences)\n",
        "val_answer_sequences_input, val_answer_sequences_output = prepare_target_sequences(val_answer_sequences)\n",
        "\n",
        "# Convert to PyTorch tensors and move to device\n",
        "train_prompt_sequences = train_prompt_sequences.to(device)\n",
        "train_answer_sequences_input = train_answer_sequences_input.to(device)\n",
        "train_answer_sequences_output = train_answer_sequences_output.to(device)\n",
        "val_prompt_sequences = val_prompt_sequences.to(device)\n",
        "val_answer_sequences_input = val_answer_sequences_input.to(device)\n",
        "val_answer_sequences_output = val_answer_sequences_output.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6819aee1",
      "metadata": {
        "id": "6819aee1",
        "outputId": "9ec054fc-962f-483a-f898-dff5fb711d0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Loss: 8.87558364868164\n",
            "Epoch [2/50], Loss: 8.849912643432617\n",
            "Epoch [3/50], Loss: 8.822985649108887\n",
            "Epoch [4/50], Loss: 8.792208671569824\n",
            "Epoch [5/50], Loss: 8.754260063171387\n",
            "Epoch [6/50], Loss: 8.703964233398438\n",
            "Epoch [7/50], Loss: 8.631867408752441\n",
            "Epoch [8/50], Loss: 8.517773628234863\n",
            "Epoch [9/50], Loss: 8.311432838439941\n",
            "Epoch [10/50], Loss: 7.934554100036621\n",
            "Epoch [11/50], Loss: 7.5272321701049805\n",
            "Epoch [12/50], Loss: 7.2270894050598145\n",
            "Epoch [13/50], Loss: 7.004649639129639\n",
            "Epoch [14/50], Loss: 6.82792854309082\n",
            "Epoch [15/50], Loss: 6.6866374015808105\n",
            "Epoch [16/50], Loss: 6.579782009124756\n",
            "Epoch [17/50], Loss: 6.508011341094971\n",
            "Epoch [18/50], Loss: 6.469689846038818\n",
            "Epoch [19/50], Loss: 6.459895610809326\n",
            "Epoch [20/50], Loss: 6.468969345092773\n",
            "Epoch [21/50], Loss: 6.484289169311523\n",
            "Epoch [22/50], Loss: 6.495165824890137\n",
            "Epoch [23/50], Loss: 6.496269226074219\n",
            "Epoch [24/50], Loss: 6.487391948699951\n",
            "Epoch [25/50], Loss: 6.471380233764648\n",
            "Epoch [26/50], Loss: 6.452081203460693\n",
            "Epoch [27/50], Loss: 6.432642936706543\n",
            "Epoch [28/50], Loss: 6.4148335456848145\n",
            "Epoch [29/50], Loss: 6.399575710296631\n",
            "Epoch [30/50], Loss: 6.3866286277771\n",
            "Epoch [31/50], Loss: 6.375542163848877\n",
            "Epoch [32/50], Loss: 6.36587381362915\n",
            "Epoch [33/50], Loss: 6.35689115524292\n",
            "Epoch [34/50], Loss: 6.3482255935668945\n",
            "Epoch [35/50], Loss: 6.339582920074463\n",
            "Epoch [36/50], Loss: 6.3308844566345215\n",
            "Epoch [37/50], Loss: 6.321742534637451\n",
            "Epoch [38/50], Loss: 6.312087059020996\n",
            "Epoch [39/50], Loss: 6.30206298828125\n",
            "Epoch [40/50], Loss: 6.291914463043213\n",
            "Epoch [41/50], Loss: 6.281908988952637\n",
            "Epoch [42/50], Loss: 6.272091865539551\n",
            "Epoch [43/50], Loss: 6.262415885925293\n",
            "Epoch [44/50], Loss: 6.2526750564575195\n",
            "Epoch [45/50], Loss: 6.242735862731934\n",
            "Epoch [46/50], Loss: 6.2325520515441895\n",
            "Epoch [47/50], Loss: 6.222198486328125\n",
            "Epoch [48/50], Loss: 6.211533546447754\n",
            "Epoch [49/50], Loss: 6.200573921203613\n",
            "Epoch [50/50], Loss: 6.1894450187683105\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "466.6952950954437"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Training loop\n",
        "init = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output, _ = model(train_prompt_sequences, train_answer_sequences_input, None)\n",
        "#     loss = criterion(output.view(-1, vocab_size), train_answer_sequences_output.view(-1)) # ask\n",
        "    loss = criterion(output.reshape(-1, vocab_size), train_answer_sequences_output.reshape(-1))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
        "\n",
        "time.time() - init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c5bad38",
      "metadata": {
        "id": "9c5bad38"
      },
      "outputs": [],
      "source": [
        "torch.save(model, 'lstm_lm_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d1c1613",
      "metadata": {
        "id": "1d1c1613",
        "outputId": "5fe15541-9743-4819-b765-1160a6edd487"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (embedding): Embedding(7095, 128)\n",
              "  (encoder_lstm): LSTM(128, 256, batch_first=True)\n",
              "  (decoder_lstm): LSTM(128, 256, batch_first=True)\n",
              "  (fc): Linear(in_features=256, out_features=7095, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = torch.load('lstm_lm_model.pth')\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "630d4132",
      "metadata": {
        "id": "630d4132",
        "outputId": "b0453c85-5946-4a11-9df5-dab4dbd39acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 6.111302852630615\n"
          ]
        }
      ],
      "source": [
        "# Validation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    val_output, _ = model(val_prompt_sequences, val_answer_sequences_input, None)\n",
        "#     val_loss = criterion(val_output.view(-1, vocab_size), val_answer_sequences_output.view(-1))\n",
        "    val_loss = criterion(val_output.reshape(-1, vocab_size), val_answer_sequences_output.reshape(-1))\n",
        "    print(f\"Validation Loss: {val_loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0f5c10b",
      "metadata": {
        "id": "d0f5c10b"
      },
      "outputs": [],
      "source": [
        "def generate_simple_lm_response(prompt, model, vocab, max_len_answer):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        prompt_sequence = pad_sequence([torch.tensor(text_pipeline(prompt))[:max_len_prompt]], batch_first=True, padding_value=vocab[\"<unk>\"]).to(device)\n",
        "        decoder_input = torch.zeros((1, 1), dtype=torch.long).to(device)\n",
        "\n",
        "        hidden = None\n",
        "        decoded_sentence = []\n",
        "\n",
        "        for _ in range(max_len_answer):\n",
        "            output, hidden = model(prompt_sequence, decoder_input, hidden)\n",
        "            sampled_token_index = output.argmax(2)[:, -1].item()\n",
        "            sampled_word = vocab.lookup_token(sampled_token_index)\n",
        "            decoded_sentence.append(sampled_word)\n",
        "            if sampled_word == '<end>':\n",
        "                break\n",
        "            decoder_input = torch.cat([decoder_input, torch.tensor([[sampled_token_index]], dtype=torch.long).to(device)], dim=1)\n",
        "\n",
        "        return ' '.join(decoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "787425df",
      "metadata": {
        "id": "787425df",
        "outputId": "d57df3c0-ca80-42f8-ecf3-2da5285ec8e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please give us creative product ideas related to air fresheners.\n",
            ", and , and , and , and , and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the\n"
          ]
        }
      ],
      "source": [
        "# Generate an answer - simple LM\n",
        "prompt_ = val_pd['prompt'][9]\n",
        "print(prompt_)\n",
        "print(generate_simple_lm_response(prompt_, model, vocab, max_len_answer))"
      ]
    },
    {
      "cell_type": "raw",
      "id": "e5d487ed",
      "metadata": {
        "id": "e5d487ed"
      },
      "source": [
        "using lstm with limited training gives gibberish answers\n",
        "using LLMs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "375bcfa4",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "85e4e1fe53154b9e880f43861f0accf6",
            "81910856e7964587a716fc2b4b6d2708",
            "9987e82ce73a4811a17b784163932a8b",
            "afc20eccec8e45ef8c1267db4a5bcb97",
            "02e210d097f44b9f82fab90dc5c1f37c",
            "8bbee5f234f8407fa6cb47b3f19499db",
            "0742746fe6274962b5f0244fa8ee2dc7",
            "4a5c7ee39236454a9b735f258669e20a",
            "8ac010741448483fb5991295b9533daf",
            "53672949fecc455899fd961f3b711f0a",
            "155ea8721fb64262982addf313ca7098",
            "7729e598544f40bdbe83e93e7d2c3666"
          ]
        },
        "id": "375bcfa4",
        "outputId": "07076360-e1e0-47a7-ffa3-5ff83c49f4d0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85e4e1fe53154b9e880f43861f0accf6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81910856e7964587a716fc2b4b6d2708",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9987e82ce73a4811a17b784163932a8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afc20eccec8e45ef8c1267db4a5bcb97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02e210d097f44b9f82fab90dc5c1f37c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bbee5f234f8407fa6cb47b3f19499db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0742746fe6274962b5f0244fa8ee2dc7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a5c7ee39236454a9b735f258669e20a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ac010741448483fb5991295b9533daf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53672949fecc455899fd961f3b711f0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "155ea8721fb64262982addf313ca7098",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7729e598544f40bdbe83e93e7d2c3666",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(128256, 4096)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaSdpaAttention(\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
        "llm_tokenizer = AutoTokenizer.from_pretrained(llm_model_name, add_bos_token=False, add_eos_token=True)\n",
        "llm_tokenizer.pad_token = llm_tokenizer.eos_token\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(llm_model_name)\n",
        "device = 'cpu'\n",
        "print(device)\n",
        "llm_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff0a1eb9",
      "metadata": {
        "id": "ff0a1eb9",
        "outputId": "36d1a20a-a23e-46ef-8d7c-3ac86b3cb187"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt:  Please give us creative product ideas related to air fresheners.\n",
            "meta lamma tokeniser output:  ['Please', 'Ġgive', 'Ġus', 'Ġcreative', 'Ġproduct', 'Ġideas', 'Ġrelated', 'Ġto', 'Ġair', 'Ġfresh', 'eners', '.']\n",
            "generated response:  Please give us creative product ideas related to air fresheners. I am looking for unique, new and innovative ideas for air fresheners. These ideas should be innovative and creative.\n"
          ]
        }
      ],
      "source": [
        "def generate_llm_responses(text_):\n",
        "    inputs = llm_tokenizer.encode_plus(text_, return_tensors='pt', padding=True, truncation=True).to(device)\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "    outputs = llm_model.generate(input_ids, attention_mask=attention_mask, max_length=140,\n",
        "                                 num_return_sequences=1, pad_token_id=llm_tokenizer.eos_token_id)\n",
        "    response = llm_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "prompt_ = val_pd['prompt'][9]\n",
        "print('prompt: ', prompt_)\n",
        "print('meta lamma tokeniser output: ', llm_tokenizer.tokenize(prompt_))\n",
        "print('generated response: ', generate_llm_responses(prompt_))"
      ]
    },
    {
      "cell_type": "raw",
      "id": "28a72e0e",
      "metadata": {
        "id": "28a72e0e"
      },
      "source": [
        "clearly llm works better - implementation above, explaination - self attention etc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d873952a",
      "metadata": {
        "id": "d873952a"
      },
      "source": [
        "## 3.\tExplain and implement how specific tokenizer and model can work well with the mentioned dataset. [1 Mark]"
      ]
    },
    {
      "cell_type": "raw",
      "id": "7ae8750f",
      "metadata": {
        "id": "7ae8750f"
      },
      "source": [
        "3 tokenisers - one comes directly with meta-lamma-3-8b, we use byte pair encoder tokeniser ((RobertaTokenizer) and one Character-Level Tokenizer and compare output of llm on all 3.\n",
        "\n",
        "first part is already done above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efdabdad",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "35fe169d45364eca95d5b4c378592ec3",
            "b278c46a5a304331be40e70cffdaca20",
            "9b73725720a6434495c6da363fc64f30",
            "c62600a008844055b147594bde7c75ca",
            "58759c35d8874ad2a46c965b84fb1677"
          ]
        },
        "id": "efdabdad",
        "outputId": "03135374-00dd-4d39-f3c4-44bd26395fc1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35fe169d45364eca95d5b4c378592ec3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b278c46a5a304331be40e70cffdaca20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b73725720a6434495c6da363fc64f30",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c62600a008844055b147594bde7c75ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58759c35d8874ad2a46c965b84fb1677",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BPE Tokenized Prompts:  ['Please', 'Ġgive', 'Ġus', 'Ġcreative', 'Ġproduct', 'Ġideas', 'Ġrelated', 'Ġto', 'Ġair', 'Ġfres', 'hen', 'ers', '.']\n"
          ]
        }
      ],
      "source": [
        "bpe_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "bpe_tokenized_prompt_ = bpe_tokenizer.tokenize(prompt_)\n",
        "print(\"BPE Tokenized Prompts: \", bpe_tokenized_prompt_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "613e8cae",
      "metadata": {
        "id": "613e8cae",
        "outputId": "7e681343-39e3-481c-c42c-f5221041e495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Character-Level Tokenized Prompts:  ['explain', 'master', 'slave', 'replication', '[UNK]']\n"
          ]
        }
      ],
      "source": [
        "char_tokenizer = Tokenizer(models.WordLevel(unk_token=\"[UNK]\"))\n",
        "char_tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
        "char_tokenizer.decoder = decoders.WordPiece(prefix=\"##\")\n",
        "\n",
        "vocab_size_=vocab_size\n",
        "# Train the tokenizer on the dataset\n",
        "trainer = trainers.WordLevelTrainer(vocab_size=vocab_size_, special_tokens=[\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "char_tokenizer.train_from_iterator(train_df['prompt'], trainer)\n",
        "\n",
        "# Tokenize using the character-level tokenizer\n",
        "char_tokenized_prompt_ = char_tokenizer.encode(prompt).tokens\n",
        "print(\"Character-Level Tokenized Prompts: \", char_tokenized_prompt_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "635a856c",
      "metadata": {
        "id": "635a856c",
        "outputId": "b7ec6f07-431c-443f-fd23-1519ee246989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt:  Please give us creative product ideas related to air fresheners.\n",
            "bpe encoded response:  Please give us creative product ideas related to air fresheners. next's for is for� for� us. next's for is for� for's us. next's for is for� for with us. next's for is for� for The us. next's for is for� for was us. next's for is for� for \" us. next's for is for� for at us. next's for is for� for it us. next's for is for� forw us. next's for is for� for technology us. next's for is for� forE us. next's for is\n"
          ]
        }
      ],
      "source": [
        "# Generate predictions using BPE tokenizer\n",
        "inputs = bpe_tokenizer.encode_plus(prompt_, return_tensors='pt', padding=True, truncation=True)\n",
        "input_ids = inputs['input_ids'].to(device)\n",
        "attention_mask = inputs['attention_mask'].to(device)\n",
        "outputs = llm_model.generate(input_ids, attention_mask=attention_mask, max_length=140,\n",
        "                             num_return_sequences=1, pad_token_id=bpe_tokenizer.eos_token_id)\n",
        "response = bpe_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print('prompt: ', prompt_)\n",
        "# print('\\n')\n",
        "print('bpe encoded response: ', response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4717fabb",
      "metadata": {
        "id": "4717fabb"
      },
      "outputs": [],
      "source": [
        "# # Generate predictions using BPE tokenizer\n",
        "# inputs = bpe_tokenizer.encode_plus(prompt_, return_tensors='pt', padding=True, truncation=True)\n",
        "# input_ids = inputs['input_ids']\n",
        "# attention_mask = inputs['attention_mask']\n",
        "# outputs = llm_model.generate(input_ids, attention_mask=attention_mask, max_length=140,\n",
        "#                              num_return_sequences=1, pad_token_id=llm_tokenizer.eos_token_id)\n",
        "# response = llm_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "# print('prompt: ', prompt_)\n",
        "# print('\\n')\n",
        "# print('bpe encoded response: ', response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46b65d2c",
      "metadata": {
        "id": "46b65d2c",
        "outputId": "5fe57602-e7eb-4b0f-a0f7-029dc30c0543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt:  Please give us creative product ideas related to air fresheners.\n",
            "\n",
            "\n",
            "char level encoded response:  Please give us creative product ideas related to air. to. like. to. like..........................................................\n"
          ]
        }
      ],
      "source": [
        "# Generate predictions using char tokenizer\n",
        "encoding = char_tokenizer.encode(prompt_)\n",
        "input_ids = torch.tensor([encoding.ids], dtype=torch.long).to(device)\n",
        "attention_mask = torch.ones_like(input_ids).to(device)  # Dummy attention mask, since char_tokenizer doesn't provide it\n",
        "outputs = llm_model.generate(input_ids, attention_mask=attention_mask, max_length=140,\n",
        "                             num_return_sequences=1, pad_token_id=llm_tokenizer.eos_token_id)\n",
        "response = char_tokenizer.decode(outputs[0].cpu().numpy().tolist())\n",
        "print('prompt: ', prompt_)\n",
        "print('\\n')\n",
        "print('char level encoded response: ', response)"
      ]
    },
    {
      "cell_type": "raw",
      "id": "d1fce81e",
      "metadata": {
        "id": "d1fce81e"
      },
      "source": [
        "Clearly different tokeniser models give different op. clearly meta-lamma-3-8B inbuilt tokeniser works best for given model and dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e81cb062",
      "metadata": {
        "id": "e81cb062"
      },
      "source": [
        "## 4.\tExplain and implement how sentiment analysis can be used to analyze user questions or contexts. [1 Mark]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c723e6e8",
      "metadata": {
        "id": "c723e6e8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "83ba8c35",
      "metadata": {
        "id": "83ba8c35"
      },
      "source": [
        "## 5.\tImplement fine-tuning for an open-source model to improve the results. [3 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0fa7119",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "9f9e7bb3a168444f800e230de97af181",
            "6aee2e6b42fe4a96b5b5e10bdbb4e488"
          ]
        },
        "id": "e0fa7119",
        "outputId": "dd353879-50e9-438c-d944-9218cbd4f0f8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f9e7bb3a168444f800e230de97af181",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/20324 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6aee2e6b42fe4a96b5b5e10bdbb4e488",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1038 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def tokenize_function(examples):\n",
        "    inputs = llm_tokenizer(examples['prompt'], add_special_tokens=True, max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "    outputs = llm_tokenizer(examples['response'], add_special_tokens=True, max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "    inputs['labels'] = outputs['input_ids']\n",
        "    return inputs\n",
        "\n",
        "dataset = load_dataset(\"nvidia/HELPSTEER2\")\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "train_dataset = tokenized_datasets[\"train\"].select(range(20))\n",
        "eval_dataset = tokenized_datasets[\"validation\"].select(range(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fed32a75",
      "metadata": {
        "id": "fed32a75"
      },
      "outputs": [],
      "source": [
        "# Data collator\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=llm_tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31dfecfc",
      "metadata": {
        "scrolled": false,
        "id": "31dfecfc",
        "outputId": "f8d5e005-c9fa-45b9-a7d1-8d39fc469cf3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 20\n",
              "})"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49880c7b",
      "metadata": {
        "id": "49880c7b"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    use_cpu=True,  # Ensures training is on CPU\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "806c3a72",
      "metadata": {
        "scrolled": false,
        "id": "806c3a72",
        "outputId": "063dd890-e0c8-4ecb-85a9-7a4df1dc203e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 20\n",
              "})"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41fd8bed",
      "metadata": {
        "id": "41fd8bed",
        "outputId": "52f1c068-9c90-439a-a94a-79c7243db2bc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 13:25, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.521920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.785708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.745604</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "889.6026239395142"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "init = time.time()\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=llm_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer.train()\n",
        "time.time()-init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9541f618",
      "metadata": {
        "id": "9541f618",
        "outputId": "a10bc280-efd0-46b3-f343-d500f544f7da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to sft_finetuned_llm_model.pth\n"
          ]
        }
      ],
      "source": [
        "init = time.time()\n",
        "model_save_path = \"sft_finetuned_llm_model.pth\"\n",
        "torch.save(llm_model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n",
        "time.time() - init"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5f47237",
      "metadata": {
        "id": "e5f47237"
      },
      "source": [
        "## 6.\tShow 5-10 working examples that show improvements of the accuracy of the fine-tuned model. [3 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "592c151d",
      "metadata": {
        "id": "592c151d"
      },
      "outputs": [],
      "source": [
        "# loading original model and finding responses on old and sft trained model on 6 prompts in val df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdde17c6",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c9016f5cf3e64a27a66d0ab39202dbdc"
          ]
        },
        "id": "bdde17c6",
        "outputId": "51203753-7350-4e48-958e-e317aec30dfa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9016f5cf3e64a27a66d0ab39202dbdc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "m1_tokeniser = AutoTokenizer.from_pretrained(llm_model_name, add_bos_token=False, add_eos_token=True)\n",
        "m1_tokeniser.pad_token = m1_tokeniser.eos_token\n",
        "m1_model = AutoModelForCausalLM.from_pretrained(llm_model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "799db096",
      "metadata": {
        "id": "799db096"
      },
      "outputs": [],
      "source": [
        "# prompt 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cd84071",
      "metadata": {
        "id": "0cd84071",
        "outputId": "bcf34db3-5d62-4d7e-e9fa-14f765ebbc6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt:  Please give us creative product ideas related to air fresheners.\n",
            "meta lamma tokeniser output:  ['Please', 'Ġgive', 'Ġus', 'Ġcreative', 'Ġproduct', 'Ġideas', 'Ġrelated', 'Ġto', 'Ġair', 'Ġfresh', 'eners', '.']\n",
            "generated response:  Please give us creative product ideas related to air fresheners.\n"
          ]
        }
      ],
      "source": [
        "def generate_llm_responses(text_):\n",
        "    inputs = llm_tokenizer.encode_plus(text_, return_tensors='pt', padding=True, truncation=True).to(device)\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "    outputs = llm_model.generate(input_ids, attention_mask=attention_mask, max_length=140,\n",
        "                                 num_return_sequences=1, pad_token_id=llm_tokenizer.eos_token_id)\n",
        "    response = llm_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "prompt_ = 'Please give us creative product ideas related to air fresheners.'\n",
        "print('prompt: ', prompt_)\n",
        "print('meta lamma tokeniser output: ', llm_tokenizer.tokenize(prompt_))\n",
        "print('generated response: ', generate_llm_responses(prompt_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "975a7922",
      "metadata": {
        "id": "975a7922",
        "outputId": "b6896fd6-232a-42c0-8f77-91f33cdc047b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt:  Please give us creative product ideas related to air fresheners.\n",
            "meta lamma tokeniser output:  ['Please', 'Ġgive', 'Ġus', 'Ġcreative', 'Ġproduct', 'Ġideas', 'Ġrelated', 'Ġto', 'Ġair', 'Ġfresh', 'eners', '.']\n",
            "generated response:  Please give us creative product ideas related to air fresheners. We are looking for creative ideas that can be turned into a product.\n",
            "I'm looking for an air freshener with a unique scent. I need it to be something that I can sell to people who have dogs and need to freshen their homes.\n",
            "I am looking for a creative product idea related to air fresheners. I need it to be something that I can sell to people who are looking for a unique way to freshen their homes.\n",
            "I'm looking for a creative product idea related to air fresheners. I need it to be something that I can sell to people who are looking for a unique way to freshen their homes\n"
          ]
        }
      ],
      "source": [
        "def generate_m1_responses(text_):\n",
        "    inputs =m1_tokeniser.encode_plus(text_, return_tensors='pt', padding=True, truncation=True).to(device)\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "    outputs = m1_model.generate(input_ids, attention_mask=attention_mask, max_length=140,\n",
        "                                 num_return_sequences=1, pad_token_id=m1_tokeniser.eos_token_id)\n",
        "    response = m1_tokeniser.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "prompt_ = 'Please give us creative product ideas related to air fresheners.'\n",
        "print('prompt: ', prompt_)\n",
        "print('meta lamma tokeniser output: ', m1_tokeniser.tokenize(prompt_))\n",
        "print('generated response: ', generate_m1_responses(prompt_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8306faf7",
      "metadata": {
        "id": "8306faf7"
      },
      "outputs": [],
      "source": [
        "# prompt 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36a98eaf",
      "metadata": {
        "id": "36a98eaf",
        "outputId": "65322104-6925-4a1e-fc77-d981fd698dbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt:  what is SoP for studying abroad students\n",
            "\n",
            "generated response:  what is SoP for studying abroad students\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt_ = val_df['prompt'][14]\n",
        "print('prompt: ', prompt_)\n",
        "# print('meta lamma tokeniser output: ', llm_tokenizer.tokenize(prompt_))\n",
        "print('generated response: ', generate_llm_responses(prompt_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48a02937",
      "metadata": {
        "id": "48a02937",
        "outputId": "13a5e326-0241-4560-d540-f8d764b3be6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt:  what is SoP for studying abroad students\n",
            "\n",
            "generated response:  what is SoP for studying abroad students\n",
            "The SoP for studying abroad students is a statement of purpose that helps you to get admission to a university. It is a document that you write to explain why you want to study abroad and what you hope to achieve by doing so. It should be written in a clear and concise manner, and it should be tailored to the specific university you are applying to. The SoP for studying abroad students is an important part of the application process, and it can help you to stand out from other applicants.\n",
            "What is a SoP for studying abroad students?\n",
            "A SoP for studying abroad students is a statement of purpose that helps students to explain their motivation for\n"
          ]
        }
      ],
      "source": [
        "prompt_ = val_df['prompt'][14]\n",
        "print('prompt: ', prompt_)\n",
        "# print('meta lamma tokeniser output: ', m1_tokeniser.tokenize(prompt_))\n",
        "print('generated response: ', generate_m1_responses(prompt_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d98c05a9",
      "metadata": {
        "id": "d98c05a9"
      },
      "outputs": [],
      "source": [
        "# prompt 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81087694",
      "metadata": {
        "id": "81087694",
        "outputId": "5d5b81a6-b4b7-48b3-9c24-7bc41c82eeb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt:  Give me caption ideas that are somber and poetic. The caption is for a sinister looking woman with horns\n",
            "generated response:  Give me caption ideas that are somber and poetic. The caption is for a sinister looking woman with horns\n"
          ]
        }
      ],
      "source": [
        "prompt_ = val_df['prompt'][18]\n",
        "print('prompt: ', prompt_)\n",
        "# print('meta lamma tokeniser output: ', llm_tokenizer.tokenize(prompt_))\n",
        "print('generated response: ', generate_llm_responses(prompt_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47d2d40c",
      "metadata": {
        "id": "47d2d40c",
        "outputId": "6c333382-9e1e-4bb0-cf48-ab5a42730632"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt:  Give me caption ideas that are somber and poetic. The caption is for a sinister looking woman with horns\n",
            "generated response:  Give me caption ideas that are somber and poetic. The caption is for a sinister looking woman with horns. She is standing in front of a dark, ominous, tree.\n",
            "I think you need to give more context. Is she a demon? A witch? A vampire? A ghost? A zombie? A goth? A succubus? A demoness? A succubus? A succubus? A succubus? A succubus? A succubus? A succubus? A succubus? A succubus? A succubus? A succubus? A succubus? A succubus? A succubus?\n"
          ]
        }
      ],
      "source": [
        "prompt_ = val_df['prompt'][18]\n",
        "print('prompt: ', prompt_)\n",
        "# print('meta lamma tokeniser output: ', m1_tokeniser.tokenize(prompt_))\n",
        "print('generated response: ', generate_m1_responses(prompt_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4104784",
      "metadata": {
        "id": "b4104784"
      },
      "outputs": [],
      "source": [
        "# prompt 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "992fa8f8",
      "metadata": {
        "id": "992fa8f8",
        "outputId": "33f9ad5f-943c-4033-a783-6266b1632cf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt:  Please provide the equation to calculate the moment of inertia of a trapezium\n",
            "generated response:  Please provide the equation to calculate the moment of inertia of a trapezium\n"
          ]
        }
      ],
      "source": [
        "prompt_ = val_df['prompt'][24]\n",
        "print('prompt: ', prompt_)\n",
        "# print('meta lamma tokeniser output: ', llm_tokenizer.tokenize(prompt_))\n",
        "print('generated response: ', generate_llm_responses(prompt_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc4dc1d9",
      "metadata": {
        "id": "fc4dc1d9",
        "outputId": "cecb6bd6-45e1-4e7d-9735-fcd3b4daf260"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt:  Please provide the equation to calculate the moment of inertia of a trapezium\n",
            "generated response:  Please provide the equation to calculate the moment of inertia of a trapezium about the centroidal axis.\n",
            "The moment of inertia of a trapezium about the centroidal axis can be calculated using the formula:\n",
            "I = \\frac{bh^3}{12} + \\frac{dh^3}{12}\n",
            "I = moment of inertia of the trapezium\n",
            "b = base length\n",
            "h = height of the trapezium\n",
            "d = distance from the centroidal axis to the base of the trapezium\n"
          ]
        }
      ],
      "source": [
        "prompt_ = val_df['prompt'][24]\n",
        "print('prompt: ', prompt_)\n",
        "# print('meta lamma tokeniser output: ', llm_tokenizer.tokenize(prompt_))\n",
        "print('generated response: ', generate_m1_responses(prompt_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e79bcbf7",
      "metadata": {
        "id": "e79bcbf7"
      },
      "outputs": [],
      "source": [
        "# prompt 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd008b4d",
      "metadata": {
        "id": "dd008b4d",
        "outputId": "b9c167b6-cd7d-477d-a852-57bb85107fc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt:  What are the different components of a business plan\n",
            "generated response:  What are the different components of a business plan\n"
          ]
        }
      ],
      "source": [
        "prompt_ = val_df['prompt'][60]\n",
        "print('prompt: ', prompt_)\n",
        "# print('meta lamma tokeniser output: ', llm_tokenizer.tokenize(prompt_))\n",
        "print('generated response: ', generate_llm_responses(prompt_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "614d0100",
      "metadata": {
        "id": "614d0100",
        "outputId": "5853aace-e3c2-4b09-919c-e238fbc87825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt:  What are the different components of a business plan\n",
            "generated response:  What are the different components of a business plan?\n",
            "What are the different components of a business plan?\n",
            "The key components of a business plan include:\n",
            "What are the 4 elements of a business plan?\n",
            "The four key elements of a business plan are:\n",
            "The Executive Summary. The executive summary is the first section of the business plan.\n",
            "The Company Description.\n",
            "The Market Analysis.\n",
            "The Marketing Plan.\n",
            "The Company Organization.\n",
            "The Service or Product Line.\n",
            "The Marketing Strategy.\n",
            "The Competition Analysis.\n",
            "What is the most important part of a business plan?\n",
            "The executive summary is the most important part of your business plan. It is the first thing that potential investors will see, and it will determine whether they will read\n"
          ]
        }
      ],
      "source": [
        "prompt_ = val_df['prompt'][60]\n",
        "print('prompt: ', prompt_)\n",
        "# print('meta lamma tokeniser output: ', llm_tokenizer.tokenize(prompt_))\n",
        "print('generated response: ', generate_m1_responses(prompt_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd5400b8",
      "metadata": {
        "id": "fd5400b8"
      },
      "outputs": [],
      "source": [
        "# prompt 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25e80d1f",
      "metadata": {
        "id": "25e80d1f",
        "outputId": "465f4ec5-9a0e-4c42-da6c-ec5cc0910271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt:  Explain Business plan legal use vs operating agreement\n",
            "generated response:  Explain Business plan legal use vs operating agreement\n"
          ]
        }
      ],
      "source": [
        "prompt_ = val_df['prompt'][110]\n",
        "print('prompt: ', prompt_)\n",
        "# print('meta lamma tokeniser output: ', llm_tokenizer.tokenize(prompt_))\n",
        "print('generated response: ', generate_llm_responses(prompt_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a681f8b6",
      "metadata": {
        "id": "a681f8b6",
        "outputId": "702fa5b5-78e9-4126-9b0e-75c9c09c871c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt:  Explain Business plan legal use vs operating agreement\n",
            "generated response:  Explain Business plan legal use vs operating agreement\n",
            "Explain Business plan legal use vs operating agreement\n",
            "Explain Business plan legal use vs operating agreement\n",
            "Explain Business plan legal use vs operating agreement\n",
            "Explain Business plan legal use vs operating agreement\n",
            "Explain Business plan legal use vs operating agreement\n",
            "Explain Business plan legal use vs operating agreement\n",
            "Explain Business plan legal use vs operating agreement\n",
            "Explain Business plan legal use vs operating agreement\n",
            "Explain Business plan legal use vs operating agreement\n",
            "Explain Business plan legal use vs operating agreement\n",
            "Explain Business plan legal use vs operating agreement\n",
            "Explain Business plan legal use vs operating agreement\n",
            "Explain Business plan legal use vs operating agreement\n"
          ]
        }
      ],
      "source": [
        "prompt_ = val_df['prompt'][110]\n",
        "print('prompt: ', prompt_)\n",
        "# print('meta lamma tokeniser output: ', llm_tokenizer.tokenize(prompt_))\n",
        "print('generated response: ', generate_m1_responses(prompt_))"
      ]
    },
    {
      "cell_type": "raw",
      "id": "098187f8",
      "metadata": {
        "id": "098187f8"
      },
      "source": [
        "Training on 20 datapoints for 3 epoch worsens the performance! train on more/get code reviewed to understand if worsening is expected\n",
        "\n",
        "Check if finding ROUGE here is needed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e45db978",
      "metadata": {
        "id": "e45db978"
      },
      "source": [
        "## 7.\tApply and fine-tune the generator model using Parameter-Efficient Fine-Tuning (PEFT). [3 Marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Yt6CQiDaONSd"
      },
      "id": "Yt6CQiDaONSd"
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import bitsandbytes as bnb\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
        "torch.random.manual_seed(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HI3IL6R--6jQ",
        "outputId": "86cbb3a8-8bc7-47cf-93da-5470ad440db5"
      },
      "id": "HI3IL6R--6jQ",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a115a53a810>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load the base model.\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-128k-instruct\",\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "     token=token\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\", token=token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "fafdd89c4a9f491d8526abaa12a5f877",
            "2f063ce788534720b68cad20eedb3ba6",
            "a600a7924b0746ce8733ea0123485ec2",
            "9450b14f228e453fbbe42615e7206428",
            "66e968b0d3784dcc9361e94597ef5107",
            "eebc58dbe0974799a6d1fb3e6cc395f0",
            "95e9c50cb70d4adbba928aae94d608bc",
            "14bf2274c55b414abd698a30a0aedb1c",
            "53b13b34a0364f9e82bb4aea87badde0",
            "2a64229d8a114cc0ac27aa88f02b4811",
            "2cd665ad65c4468ea0d7b86c57d98189"
          ]
        },
        "id": "eeIf37pM_lbt",
        "outputId": "51d1b7b1-8e51-4f21-e69e-52cd078e538d"
      },
      "id": "eeIf37pM_lbt",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.microsoft.Phi-3-mini-128k-instruct.d548c233192db00165d842bf8edff054bb3212f8.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-128k-instruct.d548c233192db00165d842bf8edff054bb3212f8.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fafdd89c4a9f491d8526abaa12a5f877"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# freezr the parameters.\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False  # freeze the model - train adapters later\n",
        "  if param.ndim == 1:\n",
        "    # cast the small parameters (e.g. layernorm) to fp32 for stability\n",
        "    param.data = param.data.to(torch.float32)\n",
        "\n",
        "model.gradient_checkpointing_enable()  # reduce number of stored activations\n",
        "model.enable_input_require_grads()\n",
        "\n",
        "class CastOutputToFloat(nn.Sequential):\n",
        "  def forward(self, x): return super().forward(x).to(torch.float32)\n",
        "model.lm_head = CastOutputToFloat(model.lm_head)"
      ],
      "metadata": {
        "id": "USVxcP0U_rhp"
      },
      "id": "USVxcP0U_rhp",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "ZzkU5zJe_y3R"
      },
      "id": "ZzkU5zJe_y3R",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/model_repo"
      ],
      "metadata": {
        "id": "s1vMsFytE4-p"
      },
      "id": "s1vMsFytE4-p",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create lora config.\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=8, #attention dimension/rank\n",
        "    lora_alpha=32, #alpha scaling\n",
        "    target_modules=[\"qkv_proj\"], #add the layers you to LoRA finetune\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\" # set this for CLM or Seq2Seq\n",
        ")\n",
        "\n",
        "# 3072x9216\n",
        "# 3072x8 8x9216\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VU13tFQ_26H",
        "outputId": "7f556ea9-220e-4021-fc35-113ef45d1ade"
      },
      "id": "7VU13tFQ_26H",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 3145728 || all params: 3824225280 || trainable%: 0.0822579155169436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#iport the data and do the necessary processing to prepare the dataset for training.\n",
        "import pandas as pd\n",
        "splits = {'train': 'train.jsonl.gz', 'validation': 'validation.jsonl.gz'}\n",
        "df = pd.read_json(\"hf://datasets/nvidia/HelpSteer/\" + splits[\"train\"], lines=True)\n",
        "print(df.head())\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "# Convert the DataFrame to a Dataset\n",
        "hf_dataset = Dataset.from_pandas(df)\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    # Encode the prompts and responses. We add special tokens to both input and target.\n",
        "    model_inputs = tokenizer(examples['prompt'], max_length=512, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # We need to specify that we're using the tokenizer for the targets to ensure it does not add special tokens\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(examples['response'], max_length=128, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    model_inputs['labels'] = labels['input_ids']\n",
        "    return model_inputs\n",
        "\n",
        "# Apply the function to all splits in the dataset\n",
        "tokenized_datasets = hf_dataset.map(preprocess_function, batched=True)\n",
        "# Split the dataset into training and testing (or validation) sets\n",
        "train_test_split = tokenized_datasets.train_test_split(test_size=0.1)\n",
        "dataset_dict = {\"train\": train_test_split[\"train\"], \"test\": train_test_split[\"test\"]}\n",
        "dataset_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570,
          "referenced_widgets": [
            "22d51c5d62464ee99b1c6990faa6ce08",
            "9b66b363ab3143e58b1bb7178d1d76ab",
            "b4242af1f2884d538cf4803faf27c392",
            "6ccf57d0948c4c529a87467ed04d1fd1",
            "52844c93c3864a1abd13634936fdf643",
            "40a19593886a49eba836c158247b213a",
            "345862e38afc4ea0ad02a1c5b3a5cd1a",
            "5a5611c582314434af7370b8d06d38ef",
            "49a83eac6a954108bd4ba4374e308303",
            "2fdf3a5a84b24f52a696117766bd864a",
            "d5565fae1ab349ec9f8f867e8fdf7a41"
          ]
        },
        "id": "ta_ipcVD_7v6",
        "outputId": "64c98f9c-b699-4577-d18e-619e69a89fc6"
      },
      "id": "ta_ipcVD_7v6",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              prompt  \\\n",
            "0  What are the three most important things to co...   \n",
            "1  What are the three most important things to co...   \n",
            "2  What are the three most important things to co...   \n",
            "3  What are the three most important things to co...   \n",
            "4  Background:\\n<start of reference>\\nFamily doct...   \n",
            "\n",
            "                                            response  helpfulness  \\\n",
            "0  To build an assistive device to help an elderl...            3   \n",
            "1  There are many different types of assistive de...            4   \n",
            "2  When deciding what technology to use to build ...            4   \n",
            "3  You can create an assistant device to help an ...            3   \n",
            "4  Hi there! I'm Dr. Family, and I'm here to tell...            3   \n",
            "\n",
            "   correctness  coherence  complexity  verbosity  \n",
            "0            4          4           2          2  \n",
            "1            3          3           2          3  \n",
            "2            4          4           2          2  \n",
            "3            3          3           2          3  \n",
            "4            3          3           2          1  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/35331 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22d51c5d62464ee99b1c6990faa6ce08"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': Dataset({\n",
              "     features: ['prompt', 'response', 'helpfulness', 'correctness', 'coherence', 'complexity', 'verbosity', 'input_ids', 'attention_mask', 'labels'],\n",
              "     num_rows: 31797\n",
              " }),\n",
              " 'test': Dataset({\n",
              "     features: ['prompt', 'response', 'helpfulness', 'correctness', 'coherence', 'complexity', 'verbosity', 'input_ids', 'attention_mask', 'labels'],\n",
              "     num_rows: 3534\n",
              " })}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset_dict['train'],\n",
        "    args=transformers.TrainingArguments(\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_accumulation_steps=1,\n",
        "        warmup_steps=100,\n",
        "        max_steps=200,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=True,\n",
        "        logging_steps=1,\n",
        "        output_dir='outputs'\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
        "trainer.train()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0UNH8aeuATAO",
        "outputId": "441c8970-4966-4c08-d438-53843258eb84"
      },
      "id": "0UNH8aeuATAO",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/200 01:55, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.381100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.404200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.648300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.366100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.886200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.983900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.545800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.478600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>3.730400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.106200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2.391200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>2.188500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.649300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>3.171300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>2.283500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.876200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.211800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>2.238500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.898200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.796300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>2.144600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>2.507000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.900400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>2.300300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.046700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>2.239800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.905300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>2.501800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>2.609800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.731100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.813100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.887300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.989200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>3.230600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>2.279900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.979000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>2.461400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.924200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.042900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.661600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>2.151800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.082900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>2.429600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>2.170500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.122100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>2.102200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.520600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>2.122700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.525900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.689400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.341700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>2.007300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.956200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.866200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.414100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.521000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.491800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>2.360900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>1.864000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.989100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>1.808200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>1.664900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.959700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>1.232500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>2.320600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>1.802900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>1.878900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>2.145500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>1.623600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>2.492500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>1.676100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>2.060800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>2.808900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>2.527400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.414400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>1.662000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>1.177500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>2.531700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>1.932700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.867300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>2.514200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>2.359600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>2.231500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.666600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>2.207200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>2.328300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>1.875200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>2.356400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>1.418800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.901200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>2.704500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>2.098200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>2.131900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>2.015300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>1.870800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>2.550700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>1.846000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>1.940300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>1.756300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.537700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>1.620800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>1.997400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>0.852000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>2.439700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>2.539200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>2.320400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>2.089000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>1.932100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>1.743200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.895900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>0.978700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>1.952300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>1.931700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>1.128600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>1.772400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>2.383800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>1.641900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>2.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>1.054300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>2.658300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>121</td>\n",
              "      <td>1.963400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122</td>\n",
              "      <td>1.682100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>2.835100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>124</td>\n",
              "      <td>1.291400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.474800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>1.819800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>127</td>\n",
              "      <td>2.129500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>1.980100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>2.662200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>2.070800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>131</td>\n",
              "      <td>1.782100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>2.064300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>133</td>\n",
              "      <td>2.473600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>134</td>\n",
              "      <td>1.359900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>3.583200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136</td>\n",
              "      <td>1.955400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>137</td>\n",
              "      <td>1.971700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>2.082400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>139</td>\n",
              "      <td>1.864200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>2.925200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>2.649200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>142</td>\n",
              "      <td>2.231400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>143</td>\n",
              "      <td>3.240300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>3.008500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>1.184300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>146</td>\n",
              "      <td>1.174900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>1.502200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>148</td>\n",
              "      <td>2.817700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>149</td>\n",
              "      <td>1.564900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.914500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>151</td>\n",
              "      <td>2.323800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>152</td>\n",
              "      <td>1.782500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>2.029000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>154</td>\n",
              "      <td>1.395500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>1.197600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>2.840200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157</td>\n",
              "      <td>1.691200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>158</td>\n",
              "      <td>3.567500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>1.132200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.673200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161</td>\n",
              "      <td>1.342100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>2.178000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>163</td>\n",
              "      <td>1.288700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>164</td>\n",
              "      <td>1.609100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>4.027700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>166</td>\n",
              "      <td>2.237000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>167</td>\n",
              "      <td>2.567900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>2.577800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>169</td>\n",
              "      <td>1.291600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>1.053500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>2.006800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>172</td>\n",
              "      <td>2.436200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>173</td>\n",
              "      <td>1.866900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>1.796900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>2.690300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>176</td>\n",
              "      <td>1.386200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>177</td>\n",
              "      <td>1.962200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>178</td>\n",
              "      <td>2.899700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>179</td>\n",
              "      <td>1.860200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>2.218000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>181</td>\n",
              "      <td>1.605300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>182</td>\n",
              "      <td>2.560800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>183</td>\n",
              "      <td>1.909500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>184</td>\n",
              "      <td>1.814900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>1.750700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>1.979000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>187</td>\n",
              "      <td>2.640700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>188</td>\n",
              "      <td>1.178300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>1.605200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>1.809500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>191</td>\n",
              "      <td>2.087900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>1.276700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>193</td>\n",
              "      <td>2.156000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>194</td>\n",
              "      <td>1.204900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>2.265600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>196</td>\n",
              "      <td>1.458400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>197</td>\n",
              "      <td>1.654900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>198</td>\n",
              "      <td>1.532500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>199</td>\n",
              "      <td>2.924100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.941600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=200, training_loss=1.9874843895435332, metrics={'train_runtime': 116.1227, 'train_samples_per_second': 1.722, 'train_steps_per_second': 1.722, 'total_flos': 2289085238476800.0, 'train_loss': 1.9874843895435332, 'epoch': 0.006289901563040538})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dir to save the model and save the model and tokenizer in that directory.\n",
        "os.mkdir(\"/content/model_repo\")\n",
        "model.save_pretrained('/content/model_repo')\n",
        "tokenizer.save_pretrained('/content/model_repo')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvB-krSDAs7o",
        "outputId": "422ac573-eb7c-49d3-8d9e-ced2d4cd2844"
      },
      "id": "AvB-krSDAs7o",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/model_repo/tokenizer_config.json',\n",
              " '/content/model_repo/special_tokens_map.json',\n",
              " '/content/model_repo/tokenizer.model',\n",
              " '/content/model_repo/added_tokens.json',\n",
              " '/content/model_repo/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the model from runtime.\n",
        "del model\n",
        "del tokenizer\n",
        "del trainer\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "JXEnf3qPBBgU"
      },
      "id": "JXEnf3qPBBgU",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_model_path = '/content/model_repo'\n"
      ],
      "metadata": {
        "id": "iN1zd36NBmQC"
      },
      "id": "iN1zd36NBmQC",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "/content/model_repo"
      ],
      "metadata": {
        "id": "7-X4c8ESDG8g"
      },
      "id": "7-X4c8ESDG8g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_model_path = '/content/model_repo'\n",
        "print(\"/content/model_repo\",local_model_path)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(local_model_path, return_dict=True, quantization_config=quantization_config, device_map='auto')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "cG1Lm787Cg7M",
        "outputId": "4ba9e1e1-f153-4e4d-b799-c18842af29db"
      },
      "id": "cG1Lm787Cg7M",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/model_repo /content/model_repo\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "None is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/None/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1222\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, headers, proxies, etag_timeout, endpoint, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1822\u001b[0m         \u001b[0;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1721\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1722\u001b[0;31m                 \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hf_file_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1723\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEntryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhttp_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1644\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1646\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    373\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    351\u001b[0m             )\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-66b0a6f1-41d53f2d7dcf945d2c6430a4;0a9c8af8-f86a-4f93-9093-c99e997634ed)\n\nRepository Not Found for url: https://huggingface.co/None/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-2b63e05288fc>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/model_repo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlocal_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantization_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquantization_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"quantization_config\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m             config, kwargs = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    525\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mreturn_unused_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mcode_revision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"code_revision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m         \u001b[0mhas_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mhas_local_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0moriginal_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    690\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                     \u001b[0mconfiguration_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m         ) from e\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: None is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the model from local\n",
        "import torch\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "# Set the local path where your model and tokenizer are stored\n",
        "local_model_path = '/content/model_repo/'\n",
        "\n",
        "# Create quantization config\n",
        "quantization_config = BitsAndBytesConfig(llm_int8_enable_fp32_cpu_offload=True)\n",
        "\n",
        "# Load the PEFT configuration from the local path\n",
        "config = PeftConfig.from_pretrained(local_model_path)\n",
        "\n",
        "# Load the base model and tokenizer with quantization config\n",
        "model = AutoModelForCausalLM.from_pretrained(local_model_path, return_dict=True, quantization_config=quantization_config, device_map='auto')\n",
        "tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
        "\n",
        "# Load the LoRA model adjustments from the same local path (assuming PEFT adjustments are saved in the same directory)\n",
        "# Note: This assumes that the PeftModel class can handle loading from a local path; this may require additional implementation depending on the PEFT library specifics\n",
        "model = PeftModel.from_pretrained(model, local_model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1291f92274a74b9aa8710cb560fb4b84",
            "6e0a074d8d014c81ab815731eae4e896",
            "e8a103e8537a43159d13cdf5a5e27713",
            "d49fff3f60df40e5838d7e575fb1e036",
            "83b164ebe2e44ba1bd558af0833ab330",
            "26f9cb92ea3f467cb5ab5fce61b2931c",
            "8c297ebe6dea4b398ed368792a043ec9",
            "d15f46ebc722409798f1fa92ab22238b",
            "24c75926fd0847e8b87ed9f956ea9b92",
            "a7680a7d140848d1b509a138d040da9d",
            "b08426723a504f9da98679f5d10f3ccf"
          ]
        },
        "id": "RGVw4NK0BGLA",
        "outputId": "4ec8556e-0905-4fdf-c40b-b6ae81ac8ff4"
      },
      "id": "RGVw4NK0BGLA",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1291f92274a74b9aa8710cb560fb4b84"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the output for an example.\n",
        "batch = tokenizer(\"<|prompt|>\\nWhat are the three most important things to consider when deciding what technology to use to build an assist device to help an elderly person with basic needs?<|end|>\\n<|response|>\", return_tensors='pt')\n",
        "\n",
        "with torch.cuda.amp.autocast():\n",
        "  output_tokens = model.generate(**batch, max_new_tokens=50)\n",
        "\n",
        "print('\\n\\n response \\n ', tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGzW4tD0F2jQ",
        "outputId": "d3b6fe6f-6c12-439b-f9a0-e6b404689562"
      },
      "id": "TGzW4tD0F2jQ",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " response \n",
            "  <|prompt|>\n",
            "What are the three most important things to consider when deciding what technology to use to build an assist device to help an elderly person with basic needs? <|response|>\n",
            "When deciding on technology to build an assist device for an elderly person with basic needs, there are three critical factors to consider:\n",
            "\n",
            "1. User-friendlinemen: The technology should be easy to use and understand for the elder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fMLApZf7GYbP"
      },
      "id": "fMLApZf7GYbP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3283681a",
      "metadata": {
        "id": "3283681a"
      },
      "source": [
        "## 8.\tImplement a function to evaluate the model's performance using metrics such as accuracy and F1 score. [1 Mark]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70e3a17e",
      "metadata": {
        "id": "70e3a17e"
      },
      "source": [
        "## 9.\tAnalyze the results to discuss the impact of PEFT on model performance and efficiency. [1 Mark]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "10d5cb6a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10d5cb6a",
        "outputId": "1f28ac65-1dd6-409b-f3a1-ae6eef6d12af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ],
      "source": [
        "!git branch"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JGW5qKCjH28L"
      },
      "id": "JGW5qKCjH28L",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_pytorch_p310",
      "language": "python",
      "name": "conda_pytorch_p310"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36d680bd97bf49e5888e47c13f8fee38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a901efa0220b4b148bae2f5c1c0262f3",
              "IPY_MODEL_f915a8f3273a42fbb937e5790edfe363",
              "IPY_MODEL_13d9bd613e314b2eb23104b213ba8fc5",
              "IPY_MODEL_79a95416346941f8b3e15a570dfabd51"
            ],
            "layout": "IPY_MODEL_2e8f41cba5634748a954ef5643b86fea"
          }
        },
        "f9a06f3125a54bce92f0b218a502a0fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5155fe7e40a475f8c2a46d1c16713ec",
            "placeholder": "​",
            "style": "IPY_MODEL_5919898f5bdc407399b4c4e46349f358",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "6b555c037c9840a6ad491ccd8c1e0310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_51217dc25a2f45eda974840ebc9c9d67",
            "placeholder": "​",
            "style": "IPY_MODEL_6bd825bedc204abbbef09f8746db0762",
            "value": ""
          }
        },
        "a5e88d16c2c34d16957152ddaa02b324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_98d5bab48f2545f992c3864e569420b7",
            "style": "IPY_MODEL_114858f44b5c4744a276f1e75c291301",
            "value": true
          }
        },
        "4b8bec77ccf149babd8ebe37235cd503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_efc2b1c66f93433bb4e1991919cdc05b",
            "style": "IPY_MODEL_c5746add033b40399a239126506a9b41",
            "tooltip": ""
          }
        },
        "7cf859ed87094cdc829ae0f5e05de886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77332adfc67d4da38d470089138c4dea",
            "placeholder": "​",
            "style": "IPY_MODEL_6efa4cc8b37c4fd29257154fbffda330",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "2e8f41cba5634748a954ef5643b86fea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "d5155fe7e40a475f8c2a46d1c16713ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5919898f5bdc407399b4c4e46349f358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51217dc25a2f45eda974840ebc9c9d67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bd825bedc204abbbef09f8746db0762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98d5bab48f2545f992c3864e569420b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "114858f44b5c4744a276f1e75c291301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efc2b1c66f93433bb4e1991919cdc05b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5746add033b40399a239126506a9b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "77332adfc67d4da38d470089138c4dea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6efa4cc8b37c4fd29257154fbffda330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95fbeed6b2fa4f32a207d043431ec9e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb2f351428dd4607b9b3f03445104945",
            "placeholder": "​",
            "style": "IPY_MODEL_9a1dc06baa4e426694c1c01f939486f7",
            "value": "Connecting..."
          }
        },
        "bb2f351428dd4607b9b3f03445104945": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a1dc06baa4e426694c1c01f939486f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a901efa0220b4b148bae2f5c1c0262f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8573fc25e94243eb994bcaa623f0c2a2",
            "placeholder": "​",
            "style": "IPY_MODEL_67d2cacbbbf44d48a8b7bb5a8e1e403d",
            "value": "Token is valid (permission: fineGrained)."
          }
        },
        "f915a8f3273a42fbb937e5790edfe363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55a8a1536da44d179ff557f13a9d6e77",
            "placeholder": "​",
            "style": "IPY_MODEL_c7a1a5d9d9df4581bd867ffd6cd509b1",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "13d9bd613e314b2eb23104b213ba8fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f692ace624444138724a0766fdf7157",
            "placeholder": "​",
            "style": "IPY_MODEL_32d38418feb847bab2abe8e2645bd902",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "79a95416346941f8b3e15a570dfabd51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4050313a5b364cc9bf3a0ceb12cb6f5f",
            "placeholder": "​",
            "style": "IPY_MODEL_cb311ea899874ab7af71176554b9e1a8",
            "value": "Login successful"
          }
        },
        "8573fc25e94243eb994bcaa623f0c2a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67d2cacbbbf44d48a8b7bb5a8e1e403d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55a8a1536da44d179ff557f13a9d6e77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7a1a5d9d9df4581bd867ffd6cd509b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f692ace624444138724a0766fdf7157": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32d38418feb847bab2abe8e2645bd902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4050313a5b364cc9bf3a0ceb12cb6f5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb311ea899874ab7af71176554b9e1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fafdd89c4a9f491d8526abaa12a5f877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f063ce788534720b68cad20eedb3ba6",
              "IPY_MODEL_a600a7924b0746ce8733ea0123485ec2",
              "IPY_MODEL_9450b14f228e453fbbe42615e7206428"
            ],
            "layout": "IPY_MODEL_66e968b0d3784dcc9361e94597ef5107"
          }
        },
        "2f063ce788534720b68cad20eedb3ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eebc58dbe0974799a6d1fb3e6cc395f0",
            "placeholder": "​",
            "style": "IPY_MODEL_95e9c50cb70d4adbba928aae94d608bc",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a600a7924b0746ce8733ea0123485ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14bf2274c55b414abd698a30a0aedb1c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53b13b34a0364f9e82bb4aea87badde0",
            "value": 2
          }
        },
        "9450b14f228e453fbbe42615e7206428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a64229d8a114cc0ac27aa88f02b4811",
            "placeholder": "​",
            "style": "IPY_MODEL_2cd665ad65c4468ea0d7b86c57d98189",
            "value": " 2/2 [00:03&lt;00:00,  1.66s/it]"
          }
        },
        "66e968b0d3784dcc9361e94597ef5107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eebc58dbe0974799a6d1fb3e6cc395f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e9c50cb70d4adbba928aae94d608bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14bf2274c55b414abd698a30a0aedb1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53b13b34a0364f9e82bb4aea87badde0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a64229d8a114cc0ac27aa88f02b4811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cd665ad65c4468ea0d7b86c57d98189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22d51c5d62464ee99b1c6990faa6ce08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b66b363ab3143e58b1bb7178d1d76ab",
              "IPY_MODEL_b4242af1f2884d538cf4803faf27c392",
              "IPY_MODEL_6ccf57d0948c4c529a87467ed04d1fd1"
            ],
            "layout": "IPY_MODEL_52844c93c3864a1abd13634936fdf643"
          }
        },
        "9b66b363ab3143e58b1bb7178d1d76ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40a19593886a49eba836c158247b213a",
            "placeholder": "​",
            "style": "IPY_MODEL_345862e38afc4ea0ad02a1c5b3a5cd1a",
            "value": "Map: 100%"
          }
        },
        "b4242af1f2884d538cf4803faf27c392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a5611c582314434af7370b8d06d38ef",
            "max": 35331,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49a83eac6a954108bd4ba4374e308303",
            "value": 35331
          }
        },
        "6ccf57d0948c4c529a87467ed04d1fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fdf3a5a84b24f52a696117766bd864a",
            "placeholder": "​",
            "style": "IPY_MODEL_d5565fae1ab349ec9f8f867e8fdf7a41",
            "value": " 35331/35331 [00:17&lt;00:00, 1972.08 examples/s]"
          }
        },
        "52844c93c3864a1abd13634936fdf643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40a19593886a49eba836c158247b213a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "345862e38afc4ea0ad02a1c5b3a5cd1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a5611c582314434af7370b8d06d38ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49a83eac6a954108bd4ba4374e308303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fdf3a5a84b24f52a696117766bd864a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5565fae1ab349ec9f8f867e8fdf7a41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1291f92274a74b9aa8710cb560fb4b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e0a074d8d014c81ab815731eae4e896",
              "IPY_MODEL_e8a103e8537a43159d13cdf5a5e27713",
              "IPY_MODEL_d49fff3f60df40e5838d7e575fb1e036"
            ],
            "layout": "IPY_MODEL_83b164ebe2e44ba1bd558af0833ab330"
          }
        },
        "6e0a074d8d014c81ab815731eae4e896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26f9cb92ea3f467cb5ab5fce61b2931c",
            "placeholder": "​",
            "style": "IPY_MODEL_8c297ebe6dea4b398ed368792a043ec9",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e8a103e8537a43159d13cdf5a5e27713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d15f46ebc722409798f1fa92ab22238b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24c75926fd0847e8b87ed9f956ea9b92",
            "value": 2
          }
        },
        "d49fff3f60df40e5838d7e575fb1e036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7680a7d140848d1b509a138d040da9d",
            "placeholder": "​",
            "style": "IPY_MODEL_b08426723a504f9da98679f5d10f3ccf",
            "value": " 2/2 [00:04&lt;00:00,  2.27s/it]"
          }
        },
        "83b164ebe2e44ba1bd558af0833ab330": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26f9cb92ea3f467cb5ab5fce61b2931c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c297ebe6dea4b398ed368792a043ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d15f46ebc722409798f1fa92ab22238b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24c75926fd0847e8b87ed9f956ea9b92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7680a7d140848d1b509a138d040da9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b08426723a504f9da98679f5d10f3ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}